# hadoopproxy
This project is to assist normal users who are not familiar with hadoop to utilize an existing hadoop environment to run parallel jobs. The simple idea is to make the existing hadoop enviroment be a thread pool. The user does not need to know how to write map/reduce function or how to submit a hadoop job. The proxy is a container of threads. The user only needs to insert his(or her) created threads into the container and invoke the execution function. Then, the proxy will automatically send these threads to the hadoop master server and transform them into map/reduce functions.
